{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_layers import PositionalEncoding, Encoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioEncoder(nn.Module):\n",
    "    def __init__(self, n_mels=80, n_ctx=1500, d_model=512, n_head=8, \n",
    "                 n_layer=6, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_mels = n_mels\n",
    "        self.n_ctx = n_ctx  # context length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 兩層1D卷積用於特徵提取\n",
    "        self.conv1 = nn.Conv1d(n_mels, d_model, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len=n_ctx)\n",
    "        \n",
    "        # Transformer編碼器層\n",
    "        self.encoder = Encoder(d_model, n_head, d_ff, n_layer, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 通過卷積層提取特徵\n",
    "        x = F.gelu(self.conv1(x))\n",
    "        x = F.gelu(self.conv2(x))\n",
    "        \n",
    "        # 轉換維度順序: (batch, d_model, time) -> (batch, time, d_model)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 添加位置編碼\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # 通過Transformer編碼器\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_layers import Decoder\n",
    "import torch\n",
    "\n",
    "class TextDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size=51865, n_ctx=448, d_model=512, n_head=8,\n",
    "                 n_layer=6, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_ctx = n_ctx\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Token嵌入層\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # Whisper解碼器使用可學習的位置嵌入\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(n_ctx, d_model) * 0.01)\n",
    "        \n",
    "        # Transformer解碼器層\n",
    "        self.decoder = Decoder(d_model, n_head, d_ff, n_layer, dropout)\n",
    "        \n",
    "        # 最終的線性層，輸出詞彙表大小的分佈\n",
    "        self.ln_f = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, tokens, audio_features, mask=None):\n",
    "        # Token嵌入\n",
    "        x = self.token_embedding(tokens)\n",
    "        \n",
    "        # 添加可學習的位置嵌入\n",
    "        seq_len = tokens.size(1)\n",
    "        x = x + self.positional_embedding[:seq_len]\n",
    "        \n",
    "        # 生成因果遮罩（causal mask）\n",
    "        if mask is None:\n",
    "            mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "            if tokens.is_cuda:\n",
    "                mask = mask.cuda()\n",
    "        \n",
    "        # 通過Transformer解碼器\n",
    "        x = self.decoder(x, audio_features, tgt_mask=mask)\n",
    "        \n",
    "        # 最終層正規化和線性變換\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79496ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "class Whisper(nn.Module):\n",
    "    def __init__(self, \n",
    "                 # 音頻編碼器參數\n",
    "                 n_mels=80, audio_ctx=1500, \n",
    "                 # 文本解碼器參數  \n",
    "                 vocab_size=51865, text_ctx=448,\n",
    "                 # 模型參數\n",
    "                 d_model=512, n_head=8, n_layer=6, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 音頻編碼器\n",
    "        self.encoder = AudioEncoder(\n",
    "            n_mels=n_mels,\n",
    "            n_ctx=audio_ctx,\n",
    "            d_model=d_model,\n",
    "            n_head=n_head,\n",
    "            n_layer=n_layer,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # 文本解碼器\n",
    "        self.decoder = TextDecoder(\n",
    "            vocab_size=vocab_size,\n",
    "            n_ctx=text_ctx,\n",
    "            d_model=d_model,\n",
    "            n_head=n_head,\n",
    "            n_layer=n_layer,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # 特殊token的定義\n",
    "        self.sot_token = 50258  # start of transcript\n",
    "        self.eot_token = 50257  # end of transcript\n",
    "        self.no_speech_token = 50362\n",
    "        \n",
    "    def forward(self, mel, tokens=None, attention_mask=None):\n",
    "        # 編碼音頻\n",
    "        audio_features = self.encoder(mel)\n",
    "        \n",
    "\n",
    "        logits = self.decoder(tokens, audio_features, mask=attention_mask)\n",
    "        return logits\n",
    " \n",
    "    \n",
    "    def generate(self, mel, max_length=448, temperature=1.0, top_p=0.9):\n",
    "        self.eval()\n",
    "        batch_size = mel.size(0)\n",
    "        device = mel.device\n",
    "        \n",
    "        # 編碼音頻\n",
    "        with torch.no_grad():\n",
    "            audio_features = self.encoder(mel)\n",
    "        \n",
    "        # 初始化解碼序列與 attention mask\n",
    "        tokens = torch.tensor([[self.sot_token]] * batch_size, device=device)\n",
    "        attn_mask = torch.ones_like(tokens, dtype=torch.long)\n",
    "        \n",
    "        for i in range(max_length - 1):\n",
    "            with torch.no_grad():\n",
    "                logits = self.decoder(tokens, audio_features, attention_mask=attn_mask)\n",
    "                \n",
    "                # 取最後一個位置的logits\n",
    "                next_token_logits = logits[:, -1, :] / temperature\n",
    "                \n",
    "                # Greedy decoding\n",
    "                next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "                \n",
    "                # 添加到序列中\n",
    "                tokens = torch.cat([tokens, next_token], dim=1)\n",
    "                \n",
    "                # 更新 attention mask\n",
    "                next_mask = torch.ones((batch_size, 1), dtype=torch.long, device=device)\n",
    "                attn_mask = torch.cat([attn_mask, next_mask], dim=1)\n",
    "                \n",
    "                # 檢查是否遇到結束token\n",
    "                if (next_token == self.eot_token).all():\n",
    "                    break\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 使用範例\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化 Whisper Tokenizer\n",
    "    tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\")\n",
    "    \n",
    "    # 創建一個base規模的Whisper模型\n",
    "    model =  Whisper(\n",
    "        d_model=1280, n_head=20, n_layer=32, d_ff=5120,\n",
    "        audio_ctx=1500, text_ctx=448\n",
    "    )\n",
    "    # 模擬輸入\n",
    "    batch_size = 2\n",
    "    n_mels = 80\n",
    "    time_steps = 3000\n",
    "    text_list = [\"hello world\", \"this is whisper\"]\n",
    "    \n",
    "    # 創建模擬的mel-spectrogram\n",
    "    mel = torch.randn(batch_size, n_mels, time_steps)\n",
    "    \n",
    "    # 使用 tokenizer 編碼文字\n",
    "    encoded = tokenizer(text_list, return_tensors='pt', padding=True)\n",
    "    tokens = encoded['input_ids']\n",
    "    attention_mask = encoded['attention_mask']\n",
    "    \n",
    "    # 前向傳播\n",
    "    logits = model(mel, tokens, attention_mask=attention_mask)\n",
    "    print(f\"Logits shape: {logits.shape}\")  # (batch_size, seq_len, vocab_size)\n",
    "    \n",
    "    # 推理模式\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(mel, max_length=100)\n",
    "        print(f\"Generated tokens shape: {generated_tokens.shape}\")\n",
    "    \n",
    "    # 解碼生成的 tokens\n",
    "    decoded_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    for text in decoded_texts:\n",
    "        print(text)\n",
    "    \n",
    "    # 模型參數數量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195eeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a080d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
