{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉換資料型態"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定亂數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)  # 設定 Python 標準庫的亂數生成器種子\n",
    "    np.random.seed(seed)  # 設定 NumPy 亂數生成器種子\n",
    "    torch.manual_seed(seed)  # 設定 PyTorch 的 CPU 亂數生成器種子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 設定 PyTorch 在單個 GPU 上的亂數種子\n",
    "        torch.cuda.manual_seed_all(seed)  # 設定 PyTorch 在所有 GPU 上的亂數種子\n",
    "    torch.backends.cudnn.benchmark = False  # 禁用 cuDNN 的基準測試功能\n",
    "    torch.backends.cudnn.deterministic = True  # 強制 cuDNN 使用確定性算法\n",
    "\n",
    "set_seeds(2526)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "# 設定 4-bit 量化參數\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'openai/whisper-large-v3-turbo',\n",
    "    predict_timestamps=False,\n",
    "    task=\"transcribe\",\n",
    "    language='zh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperForConditionalGeneration(\n",
      "  (model): WhisperModel(\n",
      "    (encoder): WhisperEncoder(\n",
      "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (embed_positions): Embedding(1500, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x WhisperEncoderLayer(\n",
      "          (self_attn): WhisperSdpaAttention(\n",
      "            (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): WhisperDecoder(\n",
      "      (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
      "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x WhisperDecoderLayer(\n",
      "          (self_attn): WhisperSdpaAttention(\n",
      "            (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): WhisperSdpaAttention(\n",
      "            (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSpeechSeq2Seq\n",
    "\n",
    "base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    'openai/whisper-large-v3-turbo',\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "\n",
    "# 建立 LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    target_modules=['q_proj', 'v_proj']\n",
    ")\n",
    "\n",
    "# 準備模型支援量化訓練\n",
    "base_model = prepare_model_for_kbit_training(base_model, use_gradient_checkpointing=False)\n",
    "\n",
    "# 加入 LoRA 模型\n",
    "model = get_peft_model(base_model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 共有 1000 筆紀錄，開始載入音訊...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "載入音訊中: 100%|██████████| 1000/1000 [00:05<00:00, 168.28記錄/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_dataset(audio_dir, transcript_file='ASR_CN.csv', target_sr=16000):\n",
    "    df = pd.read_csv(transcript_file, encoding='utf-8-sig')\n",
    "    df['path'] = df['ID'].apply(lambda x: os.path.join(audio_dir, x))\n",
    "\n",
    "    print(f'>>> 共有 {len(df)} 筆紀錄，開始載入音訊...')\n",
    "\n",
    "    audio_list = []\n",
    "    sentence_list = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"載入音訊中\", unit=\"記錄\"):\n",
    "        wav_path = row['path']\n",
    "        sentence = row.get('sentence', '').strip()\n",
    "        audio, sr = librosa.load(wav_path, sr=target_sr, mono=True)\n",
    "\n",
    "        audio_list.append(audio)\n",
    "        sentence_list.append(sentence)\n",
    "\n",
    "    return audio_list, sentence_list\n",
    "\n",
    "audios, sentences = load_dataset('audio', 'ASR_CN.csv', target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_list, processor, sampling_rate):\n",
    "    feat = processor.feature_extractor(\n",
    "        audio_list,\n",
    "        sampling_rate=sampling_rate,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True,\n",
    "        padding='max_length',\n",
    "        max_length=sampling_rate * 30,  # 最長30秒\n",
    "        truncation=True\n",
    "    )\n",
    "    return feat['input_features'], feat['attention_mask']\n",
    "\n",
    "\n",
    "input_features, attention_mask = extract_features(audios, processor, sampling_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpeechSeq2SeqDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_features, attention_masks, sentences, processor):\n",
    "        assert len(input_features) == len(attention_masks) == len(sentences)\n",
    "        self.input_features = input_features\n",
    "        self.attention_masks = attention_masks\n",
    "        self.sentences = sentences\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_features\": self.input_features[idx],\n",
    "            \"attention_mask\": self.attention_masks[idx],\n",
    "            \"sentence\": self.sentences[idx],\n",
    "        }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input_feats = torch.stack([item['input_features'] for item in batch])\n",
    "        attention_masks = torch.stack([item['attention_mask'] for item in batch])\n",
    "        sentences = [item['sentence'] for item in batch]\n",
    "\n",
    "        # 處理 target：tokenizer 編碼句子\n",
    "        tok = self.processor.tokenizer(\n",
    "            sentences,\n",
    "            padding=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        # 對非 padding 的部分保留，其他設為 -100 以供 loss 使用\n",
    "        labels = tok['input_ids'].masked_fill(tok['attention_mask'].ne(1), -100)\n",
    "\n",
    "        return {\n",
    "            'input_features': input_feats,\n",
    "            'attention_mask': attention_masks,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 拆分資料\n",
    "feat_train, feat_valid, attn_train, attn_valid, sent_train, sent_valid = train_test_split(\n",
    "    input_features, attention_mask, sentences, train_size=0.8, random_state=2526, shuffle=True\n",
    ")\n",
    "\n",
    "# 建立 Dataset\n",
    "train_dataset = SpeechSeq2SeqDataset(feat_train, attn_train, sent_train, processor)\n",
    "valid_dataset = SpeechSeq2SeqDataset(feat_valid, attn_valid, sent_valid, processor)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=valid_dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: 100%|██████████| 200/200 [02:35<00:00,  1.28it/s, loss=1.048]\n",
      "Valid Epoch 0: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, loss=0.675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model With Loss 0.55196\n",
      "Train Loss: 1.02480 | Valid Loss: 0.55196 | Best Loss: 0.55196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 200/200 [02:35<00:00,  1.29it/s, loss=0.197]\n",
      "Valid Epoch 1: 100%|██████████| 50/50 [00:15<00:00,  3.14it/s, loss=0.580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model With Loss 0.52033\n",
      "Train Loss: 0.46845 | Valid Loss: 0.52033 | Best Loss: 0.52033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████| 200/200 [02:36<00:00,  1.27it/s, loss=0.094]\n",
      "Valid Epoch 2: 100%|██████████| 50/50 [00:15<00:00,  3.15it/s, loss=0.570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model With Loss 0.51839\n",
      "Train Loss: 0.38862 | Valid Loss: 0.51839 | Best Loss: 0.51839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████| 200/200 [02:35<00:00,  1.29it/s, loss=0.473]\n",
      "Valid Epoch 3: 100%|██████████| 50/50 [00:15<00:00,  3.14it/s, loss=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.33530 | Valid Loss: 0.52510 | Best Loss: 0.51839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████| 200/200 [02:34<00:00,  1.29it/s, loss=0.197]\n",
      "Valid Epoch 4: 100%|██████████| 50/50 [00:15<00:00,  3.18it/s, loss=0.563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.29135 | Valid Loss: 0.54468 | Best Loss: 0.51839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████| 200/200 [02:35<00:00,  1.28it/s, loss=0.123]\n",
      "Valid Epoch 5: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, loss=0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.24830 | Valid Loss: 0.54996 | Best Loss: 0.51839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|██████████| 200/200 [02:36<00:00,  1.28it/s, loss=0.061]\n",
      "Valid Epoch 6: 100%|██████████| 50/50 [00:15<00:00,  3.13it/s, loss=0.600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.21451 | Valid Loss: 0.56744 | Best Loss: 0.51839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|██████████| 200/200 [02:36<00:00,  1.28it/s, loss=0.048]\n",
      "Valid Epoch 7: 100%|██████████| 50/50 [00:15<00:00,  3.14it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.18471 | Valid Loss: 0.58050 | Best Loss: 0.51839\n",
      "\n",
      "--------------------------------------\n",
      "| Model can't improve, stop training |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LoRA model loaded from ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.encoder.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.encoder.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "from Trainer import Trainer\n",
    "import torch.optim as optim\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# 總步數 = epoch 數 * 每個 epoch 的 batch 數\n",
    "num_training_steps = len(train_loader) * 100  # 100 是總 epoch 數\n",
    "num_warmup_steps = int(0.2 * len(train_loader))  # 可調整 warmup 比例\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    epochs=100,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping=5,\n",
    "    load_best_model=True,\n",
    "    grad_clip=1.0,\n",
    "    is_lora=True\n",
    ")\n",
    "\n",
    "trainer.train(show_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用裝置：cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CER:   0%|          | 0/50 [00:00<?, ?it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Evaluating CER: 100%|██████████| 50/50 [01:05<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 平均 CER: 47.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4728323699421965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import cer\n",
    "\n",
    "def evaluate_cer_with_whisper(valid_dataloader, model, processor, device=\"auto\"):\n",
    "    # 自動選擇運算裝置\n",
    "    if device == \"auto\":    \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"使用裝置：{device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    total_chars = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    for input_datas in tqdm(valid_dataloader, desc=\"Evaluating CER\"):\n",
    "        input_datas = {k: v.to(device) for k, v in input_datas.items()} # 將資料移動到GPU上\n",
    "\n",
    "        labels = input_datas[\"labels\"]\n",
    "\n",
    "        # 產生模型輸出\n",
    "        predicted_ids = model.generate(**input_datas)\n",
    "\n",
    "        # 解碼模型預測結果與 ground truth\n",
    "        hyp = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0].strip()\n",
    "        truth = processor.batch_decode(labels, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "        # 計算 CER\n",
    "        cur_cer = cer(truth, hyp)\n",
    "        total_chars += len(truth)\n",
    "        total_errors += cur_cer * len(truth)\n",
    "        \n",
    "    average_cer = total_errors / total_chars if total_chars > 0 else 0\n",
    "    print(f\"\\n✅ 平均 CER: {average_cer:.2%}\")\n",
    "    return average_cer\n",
    "\n",
    "# 呼叫時要傳入 processor\n",
    "evaluate_cer_with_whisper(valid_loader, model, processor, device=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
