{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape: (4, 2)\n",
      "y_data shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([0, 0, 0, 1], dtype=np.float32)\n",
    "\n",
    "print(\"x_data shape:\", x_data.shape)\n",
    "print(\"y_data shape:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1):\n",
    "        # 隨機初始化w與b\n",
    "        self.w = np.random.randn(input_size)\n",
    "        self.b = np.random.randn()\n",
    "        # 設定學習率\n",
    "        self.lr = learning_rate        \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        z = np.dot(x, self.w) + self.b         # 公式 2.1：z = XW + b\n",
    "        y_hat = 1 / (1 + np.exp(-z))           # 公式 2.2：y ̂ = f(z)\n",
    "        loss = self.loss(y_hat, y)             # 公式 2.6：MSE Loss\n",
    "\n",
    "        return loss, y_hat\n",
    "       \n",
    "\n",
    "    def loss(self, y_hat, y): # MSE loss 實作\n",
    "        return 0.5 * np.mean((y_hat - y) ** 2) # 公式 2.6\n",
    "\n",
    "    def backward(self, x, y, y_hat):\n",
    "        dL_dyhat = y_hat - y                                   # ∂L/∂ŷ = ŷ - y（公式2.7）\n",
    "        dyhat_dz = y_hat * (1 - y_hat)                         # ∂ŷ/∂z = ŷ ⊙ (1 - ŷ)\n",
    "        delta = dL_dyhat * dyhat_dz                            # ∂L/∂z = (ŷ - y) ⊙ ŷ ⊙ (1 - ŷ)\n",
    "\n",
    "        grad_w = np.dot(x.T, delta) / len(x)                   # ∂L/∂W = 1/n X^T [(ŷ - y) ⊙ ŷ ⊙ (1 - ŷ)]（公式2.9）\n",
    "        grad_b = np.sum(delta) / len(x)                        # ∂L/∂b = 1/n 1^T [(ŷ - y) ⊙ ŷ ⊙ (1 - ŷ)]（公式2.10）\n",
    "\n",
    "        # 優化器更新權重 (公式2.11)\n",
    "        self.w -= self.lr * grad_w\n",
    "        self.b -= self.lr * grad_b\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        y_hat = 1 / (1 + np.exp(-z))\n",
    "\n",
    "        return y_hat, (y_hat >= 0.5).astype(int)\n",
    "    \n",
    "model = Perceptron(input_size=x_data.shape[1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 0.046753\n",
      "Epoch 2000, Loss: 0.029379\n",
      "Epoch 3000, Loss: 0.021057\n",
      "Epoch 4000, Loss: 0.016153\n",
      "Epoch 5000, Loss: 0.012961\n",
      "Epoch 6000, Loss: 0.010743\n",
      "Epoch 7000, Loss: 0.009127\n",
      "Epoch 8000, Loss: 0.007905\n",
      "Epoch 9000, Loss: 0.006952\n",
      "Epoch 10000, Loss: 0.006191\n"
     ]
    }
   ],
   "source": [
    "def train(model, x_data, y_data, epochs=10000):\n",
    "    for epoch in range(epochs):\n",
    "        loss, y_hat = model.forward(x_data, y_data)  # 前向傳播 + 損失計算\n",
    "        model.backward(x_data, y_data, y_hat)        # 反向傳播 + 參數更新\n",
    "\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss:.6f}\")\n",
    "            \n",
    "train(model, x_data, y_data, epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Results:\n",
      "Input: [0. 0.], Output: 0.0031, Predicted Class: 0\n",
      "Input: [0. 1.], Output: 0.1199, Predicted Class: 0\n",
      "Input: [1. 0.], Output: 0.1199, Predicted Class: 0\n",
      "Input: [1. 1.], Output: 0.8560, Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrediction Results:\")\n",
    "results = model.predict(x_data)\n",
    "for i in range(len(x_data)):\n",
    "    print(f\"Input: {x_data[i]}, Output: {results[0][i]:.4f}, Predicted Class: {results[1][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
